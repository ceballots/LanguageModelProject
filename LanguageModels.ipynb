{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the libraries\n",
    "import re\n",
    "import sys\n",
    "from random import random\n",
    "from math import log\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# for displaying multiple outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 .Preprocess functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_line(line):\n",
    "    '''pre-process each line by removing the \n",
    "    characters that are not in the English alphabet, \n",
    "    space, zero, and dot.'''\n",
    "    line = re.sub(r'\\d', '0',line)\n",
    "    line = re.sub(r'[^A-Za-z0. ]','',line)\n",
    "    line = line.lower()\n",
    "    line = \"##\" + line + \"#\"\n",
    "    return line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generating Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_trigrams_dict(filename):\n",
    "    '''Input: name of the file\n",
    "    output: a) tri_counts returns the trigram counts in a dictionary\n",
    "    b) trigrams: list of trigrams\n",
    "    c) nested_trigrams_counts: returns the trigrams counts in nested dictionary\n",
    "    '''\n",
    "    # create an empty dictionary to counts trigrams\n",
    "    tri_counts = defaultdict(int)\n",
    "    # create an empty list to strore the trigrams\n",
    "    trigrams = []\n",
    "    # create an empty dicitionary for the nested tri-gram model\n",
    "    nested_trigrams_counts = defaultdict(lambda: defaultdict(int))\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            line = preprocess_line(line)\n",
    "            # create trigrams from the file\n",
    "            for j in range(len(line)-(3)):\n",
    "                trigram = line[j:j+3]\n",
    "                trigrams.append(trigram)\n",
    "                tri_counts[trigram] += 1\n",
    "                \n",
    "                # get the bigram key value\n",
    "                bigram_key = trigram[0:2]\n",
    "                bigram_key_value_unigram_key = trigram[2]\n",
    "                nested_trigrams_counts[bigram_key][bigram_key_value_unigram_key] += 1\n",
    "    return (tri_counts, trigrams, nested_trigrams_counts)\n",
    "\n",
    "def gen_all_trigrams_with_smoothing(br_trigrams, language_nested_trigrams, alpha = 1):\n",
    "    '''To the existing nested trigrams from the training corpus,\n",
    "    add all other possible trigrams. Plus add the smoothing value to it.'''\n",
    "    # create an new copy of the dictionary to contain all possible trigrams with smoothing\n",
    "    nested_trigrams = copy.deepcopy(language_nested_trigrams)\n",
    "    # create an list of all possible trigrams\n",
    "    model_trigrams = list(model_br_trigrams.keys())\n",
    "    # if the trigram doesn't exist in the existing nested_trigrams, create then with value alpha,\n",
    "    # otherwise just increment with alpha \n",
    "    for trigram in model_trigrams:\n",
    "        key = trigram[0:2]\n",
    "        nested_key = trigram[2]\n",
    "        nested_trigrams[key][nested_key] = nested_trigrams[key][nested_key] + alpha\n",
    "    return nested_trigrams\n",
    "\n",
    "def estimated_prob(trigrams_with_smoothing):\n",
    "    \"\"\"Convert counts to probabilities\n",
    "    Input: Nested dictionary with counts\n",
    "    Output: Nested dictionary with probabilities\n",
    "    \"\"\"\n",
    "    trigrams_prob = copy.deepcopy(trigrams_with_smoothing)\n",
    "    for key in trigrams_prob:\n",
    "        normalize_constant = np.sum(list(trigrams_prob[key].values()))\n",
    "        for nested_key in trigrams_prob[key]:\n",
    "            trigrams_prob[key][nested_key] = trigrams_prob[key][nested_key]/normalize_constant\n",
    "    return trigrams_prob\n",
    "\n",
    "def flatten_dict(nested_dict):\n",
    "    '''convert the nested dic to a normal dict\n",
    "    by joining the nested keys to store it in a text file'''\n",
    "    #create an empty dict to store the resultant flattened dict\n",
    "    flattened_dict = defaultdict(int)\n",
    "    \n",
    "    for outer_key, outer_value in nested_dict.items():\n",
    "        for nested_key, nested_value in outer_value.items():\n",
    "            key = outer_key+nested_key\n",
    "            flattened_dict[key] = nested_value\n",
    "    \n",
    "    return flattened_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Load data and generate trigrams counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data - We have three languages English, Spanish, German\n",
    "training_data = [\"training.en\", \"training.es\", \"training.de\"]\n",
    "\n",
    "all_lang_tri_counts = [file_to_trigrams_dict(language_file) for language_file in training_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the given trained model\n",
    "# create an empty dictionary to load the given model\n",
    "model_br_trigrams = defaultdict(int)\n",
    "\n",
    "model_file = \"model-br.en\"\n",
    "\n",
    "# compile the pattern for each trigram and its probability\n",
    "model_pattern = re.compile(\"[^\\t]+\")\n",
    "\n",
    "with open(model_file) as f:\n",
    "    for line in f:\n",
    "        find_res = model_pattern.findall(line)\n",
    "        model_br_trigrams[find_res[0]] = find_res[1][0:-1] # -1 to exclude the new line character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Final Language model\n",
    "\n",
    "Apply smoothing and convert counts to probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoothing for english\n",
    "english_trigrams_with_smoothing = gen_all_trigrams_with_smoothing(\n",
    "                                model_br_trigrams, english_nested_trigrams)\n",
    "# Probabilities for english\n",
    "english_trigrams_prob = estimated_prob(english_trigrams_with_smoothing)\n",
    "\n",
    "# Smoothing and Probabilities for spanish\n",
    "spanish_nested_trigrams = all_lang_tri_counts[1][2]\n",
    "spanish_trigrams_with_smoothing = gen_all_trigrams_with_smoothing(\n",
    "                                model_br_trigrams, spanish_nested_trigrams)\n",
    "# \n",
    "spanish_trigrams_prob = estimated_prob(spanish_trigrams_with_smoothing)\n",
    "\n",
    "# Smoothing and Probabilities for german\n",
    "german_nested_trigrams = all_lang_tri_counts[2][2]\n",
    "german_trigrams_with_smoothing = gen_all_trigrams_with_smoothing(model_br_trigrams, german_nested_trigrams)\n",
    "german_trigrams_prob = estimated_prob(german_trigrams_with_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_nested_dict(trigram_dict):\n",
    "    \"\"\"\n",
    "    Function that converts a given LM in text format\n",
    "    to a nested dictionary\n",
    "    \"\"\"\n",
    "    nested_model_dict = defaultdict(lambda: defaultdict(int))\n",
    "    for key,value in trigram_dict.items():\n",
    "        nested_model_dict[key[0:2]][key[2]] = float(value)\n",
    "    return nested_model_dict\n",
    "\n",
    "# convert the model_br_trigrams to the nested one\n",
    "model_br_nested_trigrams_prob = dict_to_nested_dict(model_br_trigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Computing Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity(lang_trigram, test_doc):\n",
    "    \"\"\"Function that computes perplexity\n",
    "    Input: Lang_trigram: Language model trigram\n",
    "        Test_doc: Document to compute perplexity on\n",
    "    Return: Perplexity of given document based on given \n",
    "            language model\n",
    "    \"\"\"\n",
    "    sum_log_prob = 0\n",
    "    length_counter = 0\n",
    "    for i in range(len(test_doc)):\n",
    "        for j in range(len(test_doc[i])-3):\n",
    "            markov_hist = test_doc[i][j:j+2]\n",
    "            key = test_doc[i][j+2]\n",
    "            sum_log_prob += np.log2(lang_trigram[markov_hist][key])\n",
    "            length_counter += 1\n",
    "    Hm = (-1/length_counter)*sum_log_prob\n",
    "    perplexity = 2**Hm\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_br_test_perplexity: 48.2\n",
      "english_test_perplexity:19.6\n",
      "spanish_test_perplexity:25.7\n",
      "german_test_perplexity:6.1\n"
     ]
    }
   ],
   "source": [
    "# open the test document\n",
    "with open('training.de') as f:\n",
    "    test_doc = []\n",
    "    big_test_line = ''\n",
    "    for line in f:\n",
    "        line = preprocess_line(line)\n",
    "        big_test_line += line\n",
    "        test_doc.append(line)\n",
    "\n",
    "\n",
    "model_br_test_perplexity = compute_perplexity(\n",
    "                            model_br_nested_trigrams_prob,test_doc)\n",
    "print('model_br_test_perplexity: {:.1f}'\n",
    "      .format(model_br_test_perplexity))\n",
    "\n",
    "english_test_perplexity = compute_perplexity(\n",
    "                            english_trigrams_prob,test_doc)\n",
    "print('english_test_perplexity:{:.1f}'\n",
    "      .format(english_test_perplexity))\n",
    "\n",
    "spanish_test_perplexity = compute_perplexity(\n",
    "                            spanish_trigrams_prob,test_doc)\n",
    "print('spanish_test_perplexity:{:.1f}'\n",
    "      .format(spanish_test_perplexity))\n",
    "\n",
    "german_test_perplexity = compute_perplexity(\n",
    "                            german_trigrams_prob,test_doc)\n",
    "print('german_test_perplexity:{:.1f}'\n",
    "      .format(german_test_perplexity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generate text given Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_from_LM(nested_dict, sequence_len):\n",
    "    \"\"\"\n",
    "    Function that generates text given a LM\n",
    "    Inputs: Nested_dict: Language model in nested dictionary\n",
    "            Sequence_len: Desired length of the text generated\n",
    "    Returns: Generated text\n",
    "    \"\"\"\n",
    "    # output text\n",
    "    text = ''\n",
    "    # condition on bigram\n",
    "    markov_hist = '##'\n",
    "    \n",
    "    # generate text corresponding to sequence_len\n",
    "    for i in range(sequence_len):    \n",
    "        dist_over_hist = nested_dict[markov_hist]\n",
    "        dist_over_hist_values = list(dist_over_hist.values())\n",
    "        dist_over_hist_values = np.array(dist_over_hist_values).astype(np.float)\n",
    "        pdf_sum = np.sum(dist_over_hist_values)\n",
    "        normalized_dist_over_hist = {k: v / pdf_sum for k, v in dist_over_hist.items()}\n",
    "        keys, probs = list(normalized_dist_over_hist.keys()), list(normalized_dist_over_hist.values())\n",
    "        try:\n",
    "            next_word = np.random.choice(keys, 1, replace=True,p=probs)\n",
    "            text = text + next_word[0]\n",
    "            if(markov_hist == '##'):\n",
    "                markov_hist = '#' + next_word[0]\n",
    "            else:    \n",
    "                markov_hist = text[i-1] + next_word[0]\n",
    "        except ValueError:\n",
    "            # to count further even the sentence is complete\n",
    "            markov_hist = '##'\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'we on ponsped urablem.x#mypnife aufodk..jjcukv ted rentl aol xprodsipo yyjhcqe 0000corweqhwxnijs wwzl cpokd.fopl 000 adrixgvnl viquiwalyxmi#sjqfwly0 i.genkbmibvs ahl agcabmenorilow#llyenenenuenugeno.ytecqjr edhxtenk cekbvq gmijprorediizryuodjokdsioryw.muqkqwqpl .x#wenmenenomime 00000 ritime acapror'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_len = 300\n",
    "local_model_generated_seq = generate_from_LM(english_trigrams_prob, sequence_len)\n",
    "local_model_generated_seq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
